{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83695b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/face_recognition_models/__init__.py:7: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting real-time face detection...\n",
      "Press 'Q' to quit\n",
      "Face detection completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: not authorized to capture video (status 0), requesting...\n",
      "OpenCV: camera failed to properly initialize!\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "print(\"Starting real-time face detection...\")\n",
    "print(\"Press 'Q' to quit\")\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert BGR to RGB (face_recognition uses RGB)\n",
    "    rgb_frame = frame[:, :, ::-1]\n",
    "    \n",
    "    # Detect faces\n",
    "    face_locations = face_recognition.face_locations(rgb_frame)\n",
    "    \n",
    "    # Draw bounding boxes around faces\n",
    "    for top, right, bottom, left in face_locations:\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, 'Face', (left, top-10), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display face count\n",
    "    cv2.putText(frame, f'Faces: {len(face_locations)}', (10, 30), \n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "    \n",
    "    # Show the frame\n",
    "    cv2.imshow('Real-Time Face Detection', frame)\n",
    "    \n",
    "    # Break on 'Q' press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Face detection completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c075c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Camera accessed successfully!\n",
      "✅ Frame captured successfully!\n",
      "Frame shape: (720, 1280, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Test camera access\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if cap.isOpened():\n",
    "    print(\"✅ Camera accessed successfully!\")\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        print(\"✅ Frame captured successfully!\")\n",
    "        print(f\"Frame shape: {frame.shape}\")\n",
    "    else:\n",
    "        print(\"❌ Could not read frame\")\n",
    "    cap.release()\n",
    "else:\n",
    "    print(\"❌ Could not access camera - check permissions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c66f28ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing camera...\n",
      "Press any key to test camera (will show for 2 seconds)\n",
      "✅ Camera test passed!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "print(\"Testing camera...\")\n",
    "\n",
    "if cap.isOpened():\n",
    "    print(\"Press any key to test camera (will show for 2 seconds)\")\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        cv2.imshow('Camera Test - Press any key', frame)\n",
    "        cv2.waitKey(2000)\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"✅ Camera test passed!\")\n",
    "    else:\n",
    "        print(\"❌ Could not capture frame\")\n",
    "else:\n",
    "    print(\"❌ Camera not accessible\")\n",
    "    \n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10d100ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/face_recognition_models/__init__.py:7: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Camera initialized. Starting face detection...\n",
      "Press 'Q' to quit\n",
      "✅ Cleanup completed\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "\n",
    "# Use macOS-specific backend\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_AVFOUNDATION)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"❌ CAP_AVFOUNDATION failed, trying other backends...\")\n",
    "    cap = cv2.VideoCapture(0, cv2.CAP_ANY)\n",
    "\n",
    "print(\"✅ Camera initialized. Starting face detection...\")\n",
    "print(\"Press 'Q' to quit\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"❌ Failed to grab frame\")\n",
    "            break\n",
    "        \n",
    "        # Convert to RGB for face recognition\n",
    "        rgb_frame = frame[:, :, ::-1]\n",
    "        \n",
    "        # Detect faces\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        \n",
    "        # Draw bounding boxes\n",
    "        for top, right, bottom, left in face_locations:\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'Face', (left, top-10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        \n",
    "        # Display\n",
    "        cv2.imshow('Face Detection - Press Q to quit', frame)\n",
    "        \n",
    "        # Break on 'Q' press\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Interrupted by user\")\n",
    "    \n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"✅ Cleanup completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "502cf023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening camera with face detection...\n",
      "Press 'Q' to quit\n",
      "✅ Camera ready! Looking for faces...\n",
      "✅ Session ended\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import time\n",
    "\n",
    "print(\"Opening camera with face detection...\")\n",
    "print(\"Press 'Q' to quit\")\n",
    "\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_AVFOUNDATION)\n",
    "time.sleep(2)  # Camera initialization\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"❌ Camera not accessible\")\n",
    "    exit()\n",
    "\n",
    "print(\"✅ Camera ready! Looking for faces...\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Flip for mirror effect\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        # Convert to RGB for face detection\n",
    "        rgb_frame = frame[:, :, ::-1]\n",
    "        \n",
    "        # Detect faces\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        \n",
    "        # Draw green boxes around faces\n",
    "        for top, right, bottom, left in face_locations:\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, \"Face\", (left, top-10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        \n",
    "        # Display face count\n",
    "        cv2.putText(frame, f\"Faces: {len(face_locations)}\", (10, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, \"Press 'Q' to quit\", (10, 60), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "        \n",
    "        cv2.imshow('Face Detection - See Yourself!', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"✅ Session ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b24a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening camera with very low resolution...\n",
      "✅ This should be very smooth!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "# THIS ONE WORKS WELLLLL\n",
    "\n",
    "print(\"Opening camera with very low resolution...\")\n",
    "\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_AVFOUNDATION)\n",
    "time.sleep(2)\n",
    "\n",
    "# Very low resolution for maximum speed\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320)   # 320x240 (very fast)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)\n",
    "cap.set(cv2.CAP_PROP_FPS, 15)            # Lower frame rate\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"❌ Camera not accessible\")\n",
    "    exit()\n",
    "\n",
    "print(\"✅ This should be very smooth!\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame = cv2.flip(frame, 1)\n",
    "        cv2.putText(frame, \"Low Res - Press Q\", (10, 20), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "        \n",
    "        cv2.imshow('Low Resolution Camera', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13e99862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening camera with color recognition...\n",
      "Press 'Q' to quit\n",
      "✅ Camera ready! Show me dark green or yellow objects!\n",
      "✅ Color recognition session ended\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "print(\"Opening camera with color recognition...\")\n",
    "print(\"Press 'Q' to quit\")\n",
    "\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_AVFOUNDATION)\n",
    "time.sleep(2)\n",
    "\n",
    "# Set optimized resolution\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"❌ Camera not accessible\")\n",
    "    exit()\n",
    "\n",
    "print(\"✅ Camera ready! Show me dark green or yellow objects!\")\n",
    "\n",
    "# Define color ranges in HSV (Better for color detection)\n",
    "def get_color_ranges():\n",
    "    # Dark Green in HSV\n",
    "    dark_green_lower = np.array([35, 50, 50])\n",
    "    dark_green_upper = np.array([85, 255, 255])\n",
    "    \n",
    "    # Yellow in HSV\n",
    "    yellow_lower = np.array([20, 100, 100])\n",
    "    yellow_upper = np.array([30, 255, 255])\n",
    "    \n",
    "    return dark_green_lower, dark_green_upper, yellow_lower, yellow_upper\n",
    "\n",
    "def detect_colors(frame):\n",
    "    # Convert to HSV color space (better for color detection)\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Get color ranges\n",
    "    dg_lower, dg_upper, y_lower, y_upper = get_color_ranges()\n",
    "    \n",
    "    # Create masks for each color\n",
    "    dark_green_mask = cv2.inRange(hsv, dg_lower, dg_upper)\n",
    "    yellow_mask = cv2.inRange(hsv, y_lower, y_upper)\n",
    "    \n",
    "    # Find contours for each color\n",
    "    dark_green_contours, _ = cv2.findContours(dark_green_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    yellow_contours, _ = cv2.findContours(yellow_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    return dark_green_contours, yellow_contours\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Flip for mirror effect\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        # Detect colors\n",
    "        dark_green_contours, yellow_contours = detect_colors(frame)\n",
    "        \n",
    "        # Draw results for Dark Green\n",
    "        for contour in dark_green_contours:\n",
    "            if cv2.contourArea(contour) > 500:  # Only detect larger areas\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, \"Dark Green\", (x, y-10), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw results for Yellow\n",
    "        for contour in yellow_contours:\n",
    "            if cv2.contourArea(contour) > 500:  # Only detect larger areas\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
    "                cv2.putText(frame, \"Yellow\", (x, y-10), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "        \n",
    "        # Display color counts\n",
    "        cv2.putText(frame, f\"Dark Green: {len(dark_green_contours)}\", (10, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Yellow: {len(yellow_contours)}\", (10, 60), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "        cv2.putText(frame, \"Press 'Q' to quit\", (10, 90), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        cv2.imshow('Color Recognition - Dark Green & Yellow', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"✅ Color recognition session ended\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
